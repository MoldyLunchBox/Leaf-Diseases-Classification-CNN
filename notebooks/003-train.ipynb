{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Rescaling, Dense, Flatten, \\\n",
    "    Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config_dict = yaml.safe_load(file)\n",
    "    return Config(**config_dict)\n",
    "\n",
    "\n",
    "def generate_config(config_file):\n",
    "    \"\"\"\n",
    "    Generate a configuration file with default values.\n",
    "    \"\"\"\n",
    "    default_config = {\n",
    "        'model': \"\",\n",
    "        'epochs': 1,\n",
    "        'model_save_location': \"../models\",\n",
    "        'training_set': \"../augmented_datasets_train_transformed\",\n",
    "    }\n",
    "    with open(config_file, 'w') as file:\n",
    "        yaml.dump(default_config, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, data_set_train, model, save_path):\n",
    "        \"\"\"\n",
    "        Initialize the Trainer object.\n",
    "\n",
    "        Args:\n",
    "        - data_set_train: Training dataset.\n",
    "        - data_set_test: Test dataset.\n",
    "        - model: Path to a pre-trained model, if available.\n",
    "        \"\"\"\n",
    "        self.data_set = data_set_train\n",
    "        self.save_path = save_path\n",
    "        self.train = 0\n",
    "        self.val = 0\n",
    "        if (model):\n",
    "            self.model = tf.keras.models.load_model(model)\n",
    "        else:\n",
    "            self.model = Sequential()\n",
    "        self.history = 0\n",
    "        self.classes = []\n",
    "\n",
    "    def group_data(self):\n",
    "        \"\"\"\n",
    "        Group the training dataset into training and validation sets.\n",
    "\n",
    "        Args:\n",
    "        - training: Percentage of data to use for training.\n",
    "        - validation: Percentage of data to use for validation.\n",
    "        \"\"\"\n",
    "        train_size = int(len(self.data_set)*.95)\n",
    "        val_size = int(len(self.data_set)*.05)\n",
    "\n",
    "        self.train = self.data_set.take(train_size)\n",
    "        self.val = self.data_set.skip(train_size).take(val_size)\n",
    "\n",
    "    def save_classes(self, path):\n",
    "        \"\"\"\n",
    "        Save the classes found in the dataset.\n",
    "\n",
    "        Args:\n",
    "        - path: Directory containing the dataset.\n",
    "        \"\"\"\n",
    "        dataset_directory = path\n",
    "        class_directories = [d for d\n",
    "                             in os.listdir(dataset_directory) if\n",
    "                             os.path.isdir(os.path.join(dataset_directory, d))]\n",
    "        class_directories = sorted(class_directories)\n",
    "        self.classes = class_directories\n",
    "        print(\"Classes saved:\", class_directories)\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "        with open(self.save_path + '/labels.txt', 'w') as file:\n",
    "            for class_name in class_directories:\n",
    "                file.write(class_name + '\\n')\n",
    "\n",
    "    def build_neural_network_layers(self, model_choice):\n",
    "        \"\"\"\n",
    "        Build the neural network layers based on the chosen model\\\n",
    "            configuration.\n",
    "\n",
    "        Args:\n",
    "        - model_choice: Integer indicating the model configuration to use.\n",
    "        \"\"\"\n",
    "        if model_choice == 1:\n",
    "            self.model.add(Conv2D(16, 3, padding='same', activation='relu')),\n",
    "            self.model.add(MaxPooling2D()),\n",
    "            self.model.add(Conv2D(32, 3, padding='same', activation='relu')),\n",
    "            self.model.add(MaxPooling2D()),\n",
    "            self.model.add(Conv2D(64, 3, padding='same', activation='relu')),\n",
    "            self.model.add(MaxPooling2D()),\n",
    "            self.model.add(Flatten()),\n",
    "            self.model.add(Dense(128, activation='relu')),\n",
    "            self.model.add(Dense(8, activation='softmax')),\n",
    "        if model_choice == 2:\n",
    "            self.model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "                                  input_shape=(256, 256, 3)))\n",
    "            self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            self.model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            self.model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "            self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            self.model.add(Flatten())\n",
    "            self.model.add(Dense(512, activation='relu'))\n",
    "            self.model.add(Dropout(0.5))\n",
    "            self.model.add(Dense(256, activation='relu'))\n",
    "            self.model.add(Dropout(0.5))\n",
    "            self.model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "        if model_choice == 3:\n",
    "            self.model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "                                  input_shape=(128, 128, 3)))\n",
    "            self.model.add(MaxPooling2D((2, 2)))\n",
    "            self.model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "            self.model.add(MaxPooling2D((2, 2)))\n",
    "            self.model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "            self.model.add(MaxPooling2D((2, 2)))\n",
    "            self.model.add(Flatten())\n",
    "            self.model.add(Dense(128, activation='relu'))\n",
    "            self.model.add(Dense(64, activation='relu'))\n",
    "            self.model.add(Dense(8, activation='softmax'))\n",
    "        if model_choice == 4:\n",
    "            self.model.add(Rescaling(1.0 / 255))\n",
    "            self.model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "            self.model.add(MaxPooling2D(2, 2))\n",
    "            self.model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "            self.model.add(MaxPooling2D(2, 2))\n",
    "            self.model.add(Conv2D(32, (1, 1), activation=\"relu\"))\n",
    "            self.model.add(MaxPooling2D(2, 2))\n",
    "            self.model.add(Flatten())\n",
    "            self.model.add(Dense(512, activation=\"relu\"))\n",
    "            self.model.add(Dense(256, activation=\"relu\"))\n",
    "            self.model.add(Dense(8, activation=\"softmax\"))\n",
    "            \n",
    "\n",
    "\n",
    "        self.model.compile(optimizer='adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    def start(self, epoch):\n",
    "        \"\"\"\n",
    "        Start training the neural network.\n",
    "\n",
    "        Args:\n",
    "        - epoch: Number of epochs for training.\n",
    "        \"\"\"\n",
    "        self.history = self.model.fit(self.train, epochs=epoch)\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        Save the trained model.\n",
    "\n",
    "        Args:\n",
    "        - path: Directory to save the trained model.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        self.model.save(os.path.join(path, 'model.h5'))\n",
    "\n",
    "    def plot_history(self):\n",
    "        \"\"\"\n",
    "        Plot training history (loss and accuracy).\n",
    "        \"\"\"\n",
    "        fig = plt.figure()\n",
    "        plt.plot(self.history.history['loss'], color='teal', label='loss')\n",
    "        fig.suptitle('Loss', fontsize=20)\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.plot(self.history.history['accuracy'], color='teal', label='accuracy')\n",
    "        fig.suptitle('Accuracy', fontsize=20)\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "    def testing(self):\n",
    "        \"\"\"\n",
    "        Perform testing on the test dataset and print evaluation metrics.\n",
    "        \"\"\"\n",
    "        pre = Precision()\n",
    "        re = Recall()\n",
    "        acc = BinaryAccuracy()\n",
    "        for batch in self.test.as_numpy_iterator():\n",
    "            X, y = batch\n",
    "            yhat = self.model.predict(X)\n",
    "            pre.update_state(y, yhat)\n",
    "            re.update_state(y, yhat)\n",
    "            acc.update_state(y, yhat)\n",
    "        print(f'Precision: {pre.result().numpy()},\\\n",
    "              Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    args = load_config('config.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3984 files belonging to 8 classes.\n",
      "Classes saved: ['Apple_Black_rot', 'Apple_healthy', 'Apple_rust', 'Apple_scab', 'Grape_Black_rot', 'Grape_Esca', 'Grape_healthy', 'Grape_spot']\n"
     ]
    }
   ],
   "source": [
    "    training_data = tf.keras.utils.image_dataset_from_directory(\n",
    "        args.training_set,  image_size=(128, 128),)\n",
    "    training_data = training_data.map(lambda x, y: (x / 255, tf.one_hot(\n",
    "        y, depth=8)))\n",
    "    trainer = Trainer(training_data, args.model, args.model_save_location)\n",
    "    trainer.save_classes(args.training_set)\n",
    "    trainer.group_data()\n",
    "    if (not args.model):\n",
    "        trainer.build_neural_network_layers(3)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 33s 271ms/step - loss: 1.8538 - accuracy: 0.2895\n"
     ]
    }
   ],
   "source": [
    "    if (args.epochs):\n",
    "        trainer.start(args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in training_data:\n",
    "    print(\"Shape of an image:\", images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
